---
title: "2024 Advent of Code"
output: html_document
date: "2024-11-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(here)
library(tidylog)
`%notin%` <- negate(`%in%`)
```

## Day 1 - Places of Historical Significance

### Part 1

```{r}

#arrange both lists from lowest number to highest number, then get the absolute difference between the numbers on each row. Add these up for the answer.

day1_locations <- read_delim(here("data/day1_input.txt"), col_names = c("list1", "list2"), delim = "   ")

day1_locations_list1 <- day1_locations %>%
  select(list1) %>%
  arrange(list1)

day1_locations_list2 <- day1_locations %>%
  select(list2) %>%
  arrange(list2)

day1_locations <- day1_locations_list1 %>%
  bind_cols(day1_locations_list2)

day1_locations %>%
  mutate(diff = abs(list1 - list2)) %>%
  summarize(total_diff = sum(diff))

```

### Part 2
```{r}

#Get a similarity score for each list by finding the number of times each number in list one appears in list two, and then multiply that number by the number of times it occurs in list 2. Add all these up to get the answer.

similarity_scores <- tibble(similarity = numeric())

for (i in 1:nrow(day1_locations_list1)) {
  number <- day1_locations_list1$list1[[i]]
  times_in_list2 <- day1_locations_list2 %>%
    dplyr::filter(list2 == number) %>%
    nrow()
  similarity_score = tibble(similarity = number*times_in_list2)
  similarity_scores <- similarity_scores %>%
    bind_rows(similarity_score)
}

similarity_scores %>%
  summarize(overall_similarity = sum(similarity))

```


## Day 2 - Red Nosed Reports

### Part 1

```{r}

#each report must have numbers in increasing or decreasing order, and no greater than 3 more/less than the number before for the report to be considered safe. Number of safe reports is the answer.

temp <- file(here("data/day2_input.txt"))
day2_reports <- strsplit(readLines(temp), " ")
day2_reports <- lapply(day2_reports, as.numeric)
rm(temp)

safe_count <- 0
safe_list <- c()
unsafe_count <- 0
unsafe_list <- c()

for (i in 1:length(day2_reports)) {
  report <- day2_reports[[i]]
  if (is.unsorted(report, strictly = T) & is.unsorted(rev(report), strictly = T)) {
    unsafe_count <- unsafe_count + 1
    unsafe_list <- c(unsafe_list, i)
    print(paste("report", i, "is unsafe"))
    next
  } else {
  for (j in 2:length(report)) {
    curr_element <- report[[j]]
    prev_element <- report[[j-1]]
    
    if (abs(curr_element - prev_element) <= 3) {
      if (j == length(report)) {
        safe_count <- safe_count + 1
        safe_list <- c(safe_list, i)
        print(paste("report", i, "is safe"))
      }
    } else {
      unsafe_count <- unsafe_count + 1
      unsafe_list <- c(unsafe_list, i)
      print(paste("report", i, "is unsafe"))
      break
      }
    }
  }
}

safe_count

```

### Part 2
```{r}

#Same as Part 1, except now if only one element in a report makes it unsafe, then it can count as safe. Added unsafe_list to the above code to isolate the problematic reports... might make sense to do the whole problem in one for loop, but for now I'll do a second thing here

#Get list of unsafe reports
unsafe_reports <- day2_reports[unsafe_list]

#Make some functions to check for offenses
check_diff_too_big <- function(vec) {
  if(length(diff(vec)[abs(diff(vec)) > 3])) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}

check_out_of_order <- function(vec) {
  if(is.unsorted(vec, strictly = T) & is.unsorted(rev(vec), strictly = T)) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}


new_safe_count <- safe_count
new_unsafe_count <- unsafe_count

for (i in 1:length(unsafe_reports)) {
    vec <- unsafe_reports[[i]]
    for (j in 1:length(vec)) {
      new_vec <- vec[-j]
      
      if(check_diff_too_big(new_vec) == TRUE) {
        next
        } else if (check_out_of_order(new_vec) == TRUE) {
          next
          } else {
            #If above two are not true, report can be made safe and break out of J loop
            original_index <- which(day2_reports %in% unsafe_reports[i])
            print(paste("Report", original_index, ":", unsafe_reports[i], "can be made safe"))
            new_safe_count <- new_safe_count + 1
            new_unsafe_count <- new_unsafe_count - 1
            break
          }
      }
}

new_safe_count

```


## Day 3 - Mull it Over

### Part 1

```{r}
#find all uncorrupted multiplyer functions in the messy text file, in the format mul(X,Y)

day3_corrupted <- read_tsv(here("data/day3_input.txt"),
                           col_names = "messy") #reads in as 6 rows... I guess because of line breaks. 

mul_products <- str_extract_all(day3_corrupted$messy, "mul\\(\\d{1,3}\\,\\d{1,3}\\)") %>% 
  unlist() %>%
  str_remove(., "mul\\(") %>%
  str_remove(., "\\)") %>%
  as_tibble(.) %>%
  separate(value, into = c("mul1", "mul2"), sep = ",") %>% 
  mutate(across(everything(), as.numeric)) %>%
  mutate(product = mul1 * mul2) 

mul_products %>% 
  summarize(total = sum(product))

#------------------------------------------------------Possibly a better/faster way to do it:

day3_corrupted_text <- read_tsv(here("data/day3_input.txt"),
                           col_names = "messy") %>%
  glue::glue_collapse(.$messy) 

mul1 <- str_extract_all(day3_corrupted_text, "(?<=mul\\()\\d{1,3}(?=\\,\\d{1,3}\\))") %>%
  unlist() %>%
  parse_number(.)

mul2 <- str_extract_all(day3_corrupted_text, "(?<=mul\\(\\d{1,3}\\,)\\d{1,3}(?=\\))") %>%
  unlist() %>%
  parse_number(.)

products <- mul1*mul2

sum(products)

```

### Part 2
```{r}
# Similar to day 1, but have to remove any mul(x,y) instructions that come after the instruction don't() up to a new instruction do()

#get all rows into one for regex
corrupted <- glue::glue_collapse(day3_corrupted$messy)
#locate end of strings which is index 2 (aka beginning of good or bad stretch)
do_locations <- str_locate_all(corrupted, "do\\(\\)")[[1]][,2]
dont_locations <- str_locate_all(corrupted, "don't\\(\\)")[[1]][,2]

#get end locations for the DO and DONT calls (second half of unlisted result from str_extract)

do_ranges <- tibble(locations = c(1, do_locations,dont_locations), #the 1 is for the initial "do" state
       type = c(rep("do", length(do_locations) + 1),
                rep("dont", length(dont_locations)))) %>%
  arrange(locations) %>%
  mutate(type_num_id = data.table::rleid(type)) %>%
  group_by(type_num_id) %>%
  slice_head() %>% #if 2 dos or don'ts in a row, no need for second one (just continues the same instruction)
  ungroup() %>% 
  #now everything is in do - dont order so can pivot to get the ranges
  select(-type_num_id) %>%
  mutate(row_id = rep(1:(nrow(.)/2), each = 2)) %>%
  pivot_wider(names_from = type, values_from = locations) %>%
  select(-row_id)
  
#now get mul locations (again, just need either the start or end point, not both, since we are finding the full string which will automatically be between the ranges)
mul_locations <- str_locate_all(corrupted, "mul\\(\\d{1,3}\\,\\d{1,3}\\)")[[1]][,2]
mul_products <- mul_products %>%
  mutate(remove = FALSE)

for (i in 1:length(mul_locations)) {
  #for each mul location, check if it follows a do or a don't
  location <- mul_locations[[i]]
  in_range <- do_ranges %>%
    dplyr::filter(location >= do & location <= dont)
  if (nrow(in_range) > 0) {
    next
  } else {
    mul_products$remove[[i]] <- TRUE
  }
}

mul_products %>%
  filter(remove == FALSE) %>%
  summarize(total = sum(product))

#---------------------------------------------------A better/faster way to do it:
#extract only the do calls, don't calls, and mul calls, then filter out the don'ts


str_extract_all(day3_corrupted_text, "((?<=mul\\()\\d{1,3}\\,\\d{1,3}(?=\\)))|(do\\(\\))|(don't\\(\\))") %>%
  unlist() %>% 
  as_tibble() %>%
  mutate(do_dont = case_when(row_number() == 1 ~ "do()", 
                             TRUE ~ str_extract(value, "d.*"))) %>% 
  fill(do_dont, .direction = "down") %>% 
  filter(do_dont == "do()" & value != "do()") %>% 
  separate(value, into = c("mul1", "mul2"), sep = ",") %>% 
  mutate(across(c(mul1, mul2), as.numeric)) %>% 
  mutate(product = mul1*mul2) %>% 
  summarize(total = sum(product))

```


## Day 4 - Ceres Word Search

### Part 1

```{r}

#OOPS did it wrong the first time... put that code in the garbage chunk in case any of it is useful moving forward

#the REAL instructions are to find XMAS forward, backward or strict diagonal within the word search

#---------------------------------------Okay, trying again

day4_xmas <- read_tsv(here("data/day4_input.txt"), col_names = F) %>%
  mutate(tmp = strsplit(X1, "")) %>%
    unnest() %>%
    group_by(X1) %>%
    mutate(n = 1:n()) %>%
    pivot_wider(names_from = "n", values_from = "tmp") %>%
    ungroup() %>%
    select(-X1) %>%
  as.matrix(.)

# word search is 140 x 140

#From each X, make words from all possible orientations, then check if they are XMAS. Have to pad the matrix more to avoid going out of bounds.

day4_xmas_padded <- rbind(rep(NA, ncol(day4_xmas)+6), 
                          rep(NA, ncol(day4_xmas)+6),
                          rep(NA, ncol(day4_xmas)+6),
                          cbind(rep(NA, nrow(day4_xmas)),
                                rep(NA, nrow(day4_xmas)), 
                                rep(NA, nrow(day4_xmas)), 
                                day4_xmas, 
                                rep(NA, nrow(day4_xmas)),
                                rep(NA, nrow(day4_xmas)),
                                rep(NA, nrow(day4_xmas))),
                          rep(NA, ncol(day4_xmas)+6),
                          rep(NA, ncol(day4_xmas)+6),
                          rep(NA, ncol(day4_xmas)+6)) 

find_xmas <- function(wrdsrch, x_row, x_col) {
  possibilities <- c(
    #N
    glue::glue_collapse(na.omit(as.vector(c(
      "X", wrdsrch[x_row - 1, x_col], wrdsrch[x_row - 2, x_col], wrdsrch[x_row - 3, x_col])))),
    #NE
    glue::glue_collapse(na.omit(as.vector(c(
      "X", wrdsrch[x_row - 1, x_col + 1], wrdsrch[x_row - 2, x_col + 2], wrdsrch[x_row - 3, x_col +3])))),
    #E
    glue::glue_collapse(na.omit(as.vector(c(
      "X", wrdsrch[x_row, x_col + 1], wrdsrch[x_row, x_col + 2], wrdsrch[x_row, x_col + 3])))),
    #SE
    glue::glue_collapse(na.omit(as.vector(c(
      "X", wrdsrch[x_row + 1, x_col +1], wrdsrch[x_row + 2, x_col + 2], wrdsrch[x_row + 3, x_col +3])))),
    #S
    glue::glue_collapse(na.omit(as.vector(c(
      "X", wrdsrch[x_row + 1, x_col], wrdsrch[x_row + 2, x_col], wrdsrch[x_row + 3, x_col])))),
    #SW
    glue::glue_collapse(na.omit(as.vector(c(
      "X", wrdsrch[x_row + 1, x_col -1], wrdsrch[x_row + 2, x_col -2], wrdsrch[x_row + 3, x_col - 3])))),
    #W
    glue::glue_collapse(na.omit(as.vector(c(
      "X", wrdsrch[x_row, x_col - 1], wrdsrch[x_row, x_col - 2], wrdsrch[x_row, x_col - 3])))),
    #NW
    glue::glue_collapse(na.omit(as.vector(c(
      "X", wrdsrch[x_row - 1, x_col -1], wrdsrch[x_row - 2, x_col -2], wrdsrch[x_row - 3, x_col -3]))))
  )
  #print(possibilities)
  matches <- possibilities[possibilities == "XMAS"]
  return(length(matches))
}

x_locations <- which(day4_xmas_padded == "X", arr.ind = TRUE) #3668 Xes

xmas_count <- 0

for (i in 1:nrow(x_locations)) {
  curr_x <- x_locations[i,]
  num_matches <- find_xmas(day4_xmas_padded, curr_x[[1]], curr_x[[2]])
  xmas_count <- xmas_count + num_matches
  
}

xmas_count

```

### Part 2
```{r}

# New rules: find two MAS on the diagonal crossing... so now need to find A locations and check for diagonal M and S (somehow seems easier??)

day4_xmas_padded <- rbind(NA, cbind(NA, day4_xmas, NA), NA) #pad the matrix with NAs so the finding neighbours function works

find_x_mas <- function(wrdsrch, a_row, a_col) {
  possibilities <- c(
    #first diagonal
    glue::glue_collapse(na.omit(as.vector(c(
      wrdsrch[a_row - 1, a_col - 1], "A", wrdsrch[a_row + 1, a_col + 1])))),
    #second diagonal
    glue::glue_collapse(na.omit(as.vector(c(
      wrdsrch[a_row + 1, a_col - 1], "A", wrdsrch[a_row - 1, a_col +
                                                    1]))))
  )
  #print(possibilities)
  matches <- possibilities[possibilities %in% c("MAS", "SAM")]
  #Need full X shape to count as 1, so if we have 2 matches, return 1, otherwise 0
  if (length(matches) == 2) {
    return(1)
  } else {
    return(0)
  }
}

a_locations <- which(day4_xmas_padded == "A", arr.ind = TRUE) #4882 As

x_mas_count <- 0

for (i in 1:nrow(a_locations)) {
  curr_a <- a_locations[i,]
  num_matches <- find_x_mas(day4_xmas_padded, curr_a[[1]], curr_a[[2]])
  x_mas_count <- x_mas_count + num_matches
  
}

x_mas_count

```


## Day 5 - Print Queue

### Part 1

```{r}

#Hooo boy.... today we have to split the input data into two things, the first is the printing rules that indicate pages that must be printed before other pages (7|9 means page 7 must occur before 9) and the acutal printing jobs, which list page numbers. Have to check whether the printing orders satisfy every relevant rule, and if not, discard them. Then take the sum of all the middle page numbers.

day5_rules <- read_delim(here("data/day5_input.txt"), delim = "|",
                         col_names = c("occurs_before", "occurs_after")) %>%
  filter(!is.na(occurs_after)) %>%
  mutate(across(everything(), as.numeric))
  
#printing instructions are in a list as vectors of page numbers
day5_printing <- as.tibble(read_lines(here("data/day5_input.txt"), skip = nrow(day5_rules)+1)) %>%
  mutate(row_id = row_number()) %>%
  separate_rows(value, sep = ",") %>%
  mutate(value = as.numeric(value)) %>%
  group_by(row_id) %>%
  mutate(page_index = paste0("pg_", row_number())) %>%
  pivot_wider(names_from = page_index, values_from = value) %>%
  ungroup() %>%
  group_split(row_id) %>% 
  map(~discard(.x, is.na(.))[-1])

#how many pages are in the rules?
all_pages <- day5_rules %>% 
  pivot_longer(c(occurs_before, occurs_after), names_to = "type", values_to = "pages") %>%
  distinct(pages) %>%
  pull(pages)

num_pages_in_rules <- length(all_pages) 

#Only 49 pages involved in rules. Would it be crazy to make a vector column orderd in a way that satisfies every rule, then filter it for each printing job and check if they are identical? 

#Turns out that won't work, because some rules conflict with other rules so there is no one long chain of correct orders unfortunately. Adding that code to garbage chunk.

#that isn't working. Try iterating over each number and checking in the rules if the preceding and follwing numbers are allowed. 

get_rules <- function(input_vector) {
  printing_job <- input_vector
  relevant_rules <- day5_rules %>%
    dplyr::filter(occurs_before %in% printing_job & occurs_after %in% printing_job)
  return(relevant_rules)
}

correct_list <- c()
incorrect_list <- c()

for (i in 1:length(day5_printing)) {
  curr_printing <- day5_printing[[i]]
  curr_rules <- get_rules(curr_printing)
  for (j in 1:length(curr_printing)) {
    curr_page <- curr_printing[j]
    before_pages <- case_when(j == 1 ~ NA,
                              TRUE ~ curr_printing[1:(j-1)])
    after_pages <- case_when(j == length(curr_printing) ~ NA,
                             TRUE ~ curr_printing[(j+1):length(curr_printing)])
    before_rules <- curr_rules %>%
      dplyr::filter(occurs_after == curr_page)
    after_rules <- curr_rules %>%
      dplyr::filter(occurs_before == curr_page)
    if (any(after_pages %in% before_rules$occurs_before) | any(before_pages %in% after_rules$occurs_after)) {
      incorrect_list <- c(incorrect_list, i)
      break #if any rules are broken, whole printing job is not correct
    } else if (j == length(curr_printing)) {
      correct_list <- c(correct_list, i) #if we make it all the way to the end of j and didn't break, then the printing job is good
    }
    
  }
  
}

#Now get the middle pages

middle_indices <- floor(lengths(day5_printing[correct_list])/2)+1
correct_printing <- day5_printing[correct_list]

middle_numbers <- c()

for (i in 1:length(correct_list)) {
  middle_index <- middle_indices[i]
  middle_number <- correct_printing[[i]][middle_index]
  middle_numbers <- c(middle_numbers, middle_number)
}

sum(middle_numbers)


```

### Part 2
```{r}

#Looks like some of my original code will be useful after all! Have to turn all the incorrect printing jobs into correct ones by ordering them right.

#create function that spits out correct order
make_correct <- function(input_vector) {
  printing_job <- input_vector
  relevant_rules <- day5_rules %>%
    dplyr::filter(occurs_before %in% printing_job & occurs_after %in% printing_job)
  
  for (k in 1:length(printing_job)) {
  
  curr_page <- printing_job[[k]]
  
  if (k == 1) {
    all_pages_in_order <- c(curr_page)
  } else {
    must_be_before <- relevant_rules %>%
      dplyr::filter(occurs_before == curr_page) %>%
      dplyr::filter(occurs_after %in% all_pages_in_order) 
    if (nrow(must_be_before > 0)) {
      before_indices <- which(all_pages_in_order %in% must_be_before$occurs_after)
      before_target <- all_pages_in_order[min(before_indices)] #dplyr::filter to the lowest INDEX not value it must be before
      must_be_before <- must_be_before %>%
      dplyr::filter(occurs_after == before_target) %>%
      pull(occurs_after)
    } else {
      must_be_before <- NA
    }
    before_index <- ifelse(is.na(must_be_before), NA, which(all_pages_in_order == must_be_before))
    must_be_after <- relevant_rules %>%
      dplyr::filter(occurs_after == curr_page) %>%
      dplyr::filter(occurs_before %in% all_pages_in_order)  
    if (nrow(must_be_after > 0)) {
      after_indices <- which(all_pages_in_order %in% must_be_after$occurs_before)
      after_target <- all_pages_in_order[max(after_indices)] #filter to the highest INDEX not value it must be after
      must_be_after <- must_be_after %>%
      dplyr::filter(occurs_before == after_target) %>%
      pull(occurs_before)
    } else {
      must_be_after <- NA
    }
    after_index <- ifelse(is.na(must_be_after), NA, which(all_pages_in_order == must_be_after))
    if (is.na(before_index) & is.na(after_index)) {
      next
    } else if (!is.na(before_index)) {
      all_pages_in_order <- append(all_pages_in_order, curr_page, after = before_index - 1)
    } else {
      all_pages_in_order <- append(all_pages_in_order, curr_page, after = after_index)
    }
  }
  }
  return(all_pages_in_order)
}


incorrect_printing <- day5_printing[incorrect_list]

corrected_list <- list()

for (l in 1:length(incorrect_printing)) {
  curr_printing <- incorrect_printing[[l]]
  corrected <- make_correct(curr_printing)
  corrected_list[[l]] <- corrected
}

#Now get the middle pages

middle_indices <- floor(lengths(corrected_list)/2)+1

middle_numbers <- c()

for (i in 1:length(corrected_list)) {
  middle_index <- middle_indices[i]
  middle_number <- corrected_list[[i]][middle_index]
  middle_numbers <- c(middle_numbers, middle_number)
}

sum(middle_numbers)

```


## Day 6

### Part 1

```{r}

```

### Part 2
```{r}

```



```{r garbage}
#put code that isn't working here if you think you might need to come back to old ideas


# Must find all instances of "XMAS" in the word search, in which any of the adjacent letters can occur in any direction (up, down, diagonal). 

#Idea 1: get indices of all Xes so only have to iterate from those starting points, instead of checking every element. Then write a function to check all adjacent letters for M, then A, then S. For each X, count how many XMASes there are.

#HAHAHA I misunderstood the puzzle... the diagonals have to be fully diagonal, not zigzagging. Ugh. Keep this code anyway in case that's part 2 lol

day4_xmas <- read_tsv(here("data/day4_input.txt"), col_names = F) %>%
  mutate(tmp = strsplit(X1, "")) %>%
    unnest() %>%
    group_by(X1) %>%
    mutate(n = 1:n()) %>%
    pivot_wider(names_from = "n", values_from = "tmp") %>%
    ungroup() %>%
    select(-X1) %>%
  as.matrix(.)

day4_xmas_padded <- rbind(NA, cbind(NA, day4_xmas, NA), NA) #pad the matrix with NAs so the finding neighbours function works

# word search is 140 x 140

x_locations <- which(day4_xmas_padded == "X", arr.ind = TRUE) #3668 Xes

find_neighbours <- function(letter_row, letter_col, wrdsrch, letter_filter = ".") {
  
  neigh <- c(N  = as.vector(wrdsrch[letter_row - 1, letter_col]),
              NE = as.vector(wrdsrch[letter_row - 1, letter_col + 1]),
              E  = as.vector(wrdsrch[letter_row, letter_col + 1]),
              SE = as.vector(wrdsrch[letter_row + 1, letter_col + 1]),
              S  = as.vector(wrdsrch[letter_row + 1, letter_col    ]),
              SW = as.vector(wrdsrch[letter_row + 1, letter_col - 1]),
              W  = as.vector(wrdsrch[letter_row, letter_col - 1]),
              NW = as.vector(wrdsrch[letter_row - 1, letter_col - 1]))
  
  neigh_locs <- list(N  = c(letter_row - 1, letter_col),
              NE = c(letter_row - 1, letter_col + 1),
              E  = c(letter_row, letter_col + 1),
              SE = c(letter_row + 1, letter_col + 1),
              S  = c(letter_row + 1, letter_col    ),
              SW = c(letter_row + 1, letter_col - 1),
              W  = c(letter_row, letter_col - 1),
              NW = c(letter_row - 1, letter_col - 1))
  
  neigh <- neigh[!is.na(neigh) & str_detect(neigh, letter_filter)]
  neigh_locs <- neigh_locs[names(neigh_locs) %in% names(neigh)]
  return(list(neighbours = neigh,
              neigh_row_col = neigh_locs))
}

xmas_count <- 0

for (i in 1:nrow(x_locations)) {
  curr_x <- x_locations[i,]
  #find all the Ms next to the X
  m_locations <- find_neighbours(curr_x[[1]], curr_x[[2]], day4_xmas_padded, "M")$neigh_row_col
  print(paste("M locations for X number", i))
  if (length(m_locations) == 0) {
    next
    }
  for (j in 1:length(m_locations)) {
    curr_m <- m_locations[[j]]
    #find all the As next to the Ms
    a_locations <- find_neighbours(curr_m[[1]], curr_m[[2]], day4_xmas_padded, "A")$neigh_row_col
    print(paste("A locations for X number", i, "M number", j))
    if (length(a_locations) == 0) {
    next
    }
    for (k in 1:length(a_locations)) {
      curr_a <- a_locations[[k]]
      #find all the Ses next to the As
      s_locations <- find_neighbours(curr_a[[1]], curr_a[[2]], day4_xmas_padded, "S")$neigh_row_col
      print(paste("S locations for X number", i, "M number", j, "A number", k))
      if (length(s_locations) == 0) {
      next
      }
      xmas_count <- xmas_count + length(s_locations)
      print(paste("Adding", length(s_locations), "to the count"))
    }
  }
}

#Day 5


all_pages_in_order <- c()

for (i in 1:num_pages_in_rules) {
  
  curr_page <- all_pages[[i]]
  
  if (i == 1) {
    all_pages_in_order <- c(all_pages_in_order, curr_page)
  } else {
    must_be_before <- day5_rules %>%
      filter(occurs_before == curr_page) %>%
      filter(occurs_after %in% all_pages_in_order) 
    if (nrow(must_be_before > 0)) {
      must_be_before <- must_be_before %>%
      #filter to the lowest value it must be before
      filter(occurs_after == min(occurs_after)) %>%
      pull(occurs_after)
    } else {
      must_be_before <- NA
    }
    before_index <- ifelse(is.na(must_be_before), NA, which(all_pages_in_order == must_be_before))
    must_be_after <- day5_rules %>%
      filter(occurs_after == curr_page) %>%
      filter(occurs_before %in% all_pages_in_order)  
    if (nrow(must_be_after > 0)) {
      must_be_after <- must_be_after %>%
      #filter to the highest value it must be after
      filter(occurs_before == max(occurs_before)) %>%
      pull(occurs_before)
    } else {
      must_be_after <- NA
    }
    after_index <- ifelse(is.na(must_be_after), NA, which(all_pages_in_order == must_be_after))
    if (is.na(before_index) & is.na(after_index)) {
      next
    } else if (!is.na(before_index)) {
      all_pages_in_order <- append(all_pages_in_order, curr_page, after = before_index - 1)
    } else {
      all_pages_in_order <- append(all_pages_in_order, curr_page, after = after_index)
    }
  }
}


get_rules <- function(input_vector) {
  printing_job <- input_vector
  relevant_rules <- day5_rules %>%
    dplyr::filter(occurs_before %in% printing_job & occurs_after %in% printing_job)
  
  for (i in 1:length(printing_job)) {
  
  curr_page <- printing_job[[i]]
  
  if (i == 1) {
    all_pages_in_order <- c(curr_page)
  } else {
    must_be_before <- relevant_rules %>%
      dplyr::filter(occurs_before == curr_page) %>%
      dplyr::filter(occurs_after %in% all_pages_in_order) 
    if (nrow(must_be_before > 0)) {
      must_be_before <- must_be_before %>%
      #dplyr::filter to the lowest value it must be before
      dplyr::filter(occurs_after == min(occurs_after)) %>%
      pull(occurs_after)
    } else {
      must_be_before <- NA
    }
    before_index <- ifelse(is.na(must_be_before), NA, which(all_pages_in_order == must_be_before))
    must_be_after <- relevant_rules %>%
      dplyr::filter(occurs_after == curr_page) %>%
      dplyr::filter(occurs_before %in% all_pages_in_order)  
    if (nrow(must_be_after > 0)) {
      must_be_after <- must_be_after %>%
      #dplyr::filter to the highest value it must be after
      dplyr::filter(occurs_before == max(occurs_before)) %>%
      pull(occurs_before)
    } else {
      must_be_after <- NA
    }
    after_index <- ifelse(is.na(must_be_after), NA, which(all_pages_in_order == must_be_after))
    if (is.na(before_index) & is.na(after_index)) {
      next
    } else if (!is.na(before_index)) {
      all_pages_in_order <- append(all_pages_in_order, curr_page, after = before_index - 1)
    } else {
      all_pages_in_order <- append(all_pages_in_order, curr_page, after = after_index)
    }
  }
  }
  return(all_pages_in_order)
}

correct_list <- c()

for (i in 1:length(day5_printing)) {
  curr_printing <- day5_printing[[i]]
  curr_rules <- get_rules(curr_printing)
  if(identical(curr_rules, curr_printing)) {
    correct_list <- c(correct_list, i)
  }
}


```



